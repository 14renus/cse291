{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "\n",
    "from dataloading import *\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, inputs, targets, optimizer, criterion, computing_device):\n",
    "    model = model.to(computing_device)\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i in range(len(targets)):\n",
    "        \n",
    "        src = inputs[i].to(computing_device)\n",
    "        trg = targets[i].to(computing_device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(src, trg, teacher_forcing_ratio=1.0)\n",
    "        \n",
    "        labels = torch.argmax(trg, dim=2) # grab indices for loss function\n",
    "        \n",
    "        #targets = [trg sent len, batch size]\n",
    "        #outputs = [trg sent len, batch size, output dim]\n",
    "        \n",
    "        #print('expected')\n",
    "        #print(src.size())\n",
    "        #print(labels)\n",
    "        #print(torch.argmax(outputs, dim=2))\n",
    "        \n",
    "        #outputs = outputs[1:].view(-1, outputs.shape[-1]) \n",
    "        #labels = labels[1:].view(-1)\n",
    "        \n",
    "        outputs = outputs.view(-1, outputs.shape[-1]) \n",
    "        labels = labels.view(-1)\n",
    "        \n",
    "        outputs = outputs.to(computing_device)\n",
    "        \n",
    "        #targets = [(trg sent len - 1) * batch size]- trg should be list of indicies\n",
    "        #outputs = [(trg sent len - 1) * batch size, output dim]\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        #torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(targets)\n",
    "\n",
    "def evaluate(model, inputs, targets, optimizer, criterion, computing_device):\n",
    "    model=model.to(computing_device)\n",
    "    model.eval()\n",
    "    \n",
    "    total_loss=0.0\n",
    "    \n",
    "    for i in range(len(targets)):\n",
    "            src = inputs[i].to(computing_device)\n",
    "            trg = targets[i].to(computing_device)\n",
    "            \n",
    "            print(len(src))\n",
    "            print(len(trg))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(src, trg, teacher_forcing_ratio=0.0)\n",
    "            outputs = outputs.to(computing_device)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss+=loss\n",
    "\n",
    "            print('expected')\n",
    "            print(trg.size())\n",
    "            print(torch.argmax(trg, dim=2))\n",
    "            print(torch.argmax(outputs, dim=2))\n",
    "\n",
    "            #num_labels = interpret_output(trg)\n",
    "            #num_predictions = interpret_output(outputs)\n",
    "\n",
    "           \n",
    "\n",
    "            # shape = [seq_len, batch_size]\n",
    "            #mse = mean_squared_error(num_labels,num_predictions)\n",
    "            print('MSE',mse)\n",
    "            \n",
    "    #total_mse/=len(targets)\n",
    "    #print(total_mse)\n",
    "    #print(len(targets))\n",
    "    return total_loss/len(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is supported\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Check if your system supports CUDA\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# Setup GPU optimization if CUDA is supported\n",
    "if use_cuda:\n",
    "    computing_device = torch.device(\"cuda\")\n",
    "    extras = {\"num_workers\": 1, \"pin_memory\": True}\n",
    "    print(\"CUDA is supported\")\n",
    "else: # Otherwise, train on the CPU\n",
    "    computing_device = torch.device(\"cpu\")\n",
    "    extras = False\n",
    "    print(\"CUDA NOT supported\")\n",
    " \n",
    "computing_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "n_digits = 10\n",
    "#OUTPUT_DIM = n_digits + 2\n",
    "n_chars=256\n",
    "INPUT_DIM = n_chars+4\n",
    "OUTPUT_DIM = n_digits + 5\n",
    "#ENC_EMB_DIM = n_chars+1\n",
    "#DEC_EMB_DIM = OUTPUT_DIM\n",
    "\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.0\n",
    "DEC_DROPOUT = 0.0\n",
    "device=None\n",
    "\n",
    "enc = Encoder(INPUT_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "model = Seq2Seq(enc, dec)#.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=output_pad_index)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "{'A': ['labelled_gen_data1_A', 'labelled_gen_data3_A', 'labelled_gen_data2_A', 'labelled_extr_data1_A', 'labelled_extr_data3_A'], 'B': ['labelled_extr_data19_B', 'labelled_extr_data18_B', 'labelled_gen_data5_B', 'labelled_gen_data4_B', 'labelled_gen_data6_B'], 'C': ['labelled_gen_data10_C', 'labelled_gen_data11_C', 'labelled_gen_data7_C', 'labelled_gen_data8_C', 'labelled_gen_data9_C'], 'D': ['labelled_extr_data2_D', 'labelled_gen_data12_D', 'labelled_gen_data13_D', 'labelled_extr_data4_D'], 'E': ['labelled_extr_data20_E', 'labelled_gen_data16_E', 'labelled_dir_data91_E', 'labelled_gen_data15_E', 'labelled_dir_data92_E', 'labelled_gen_data14_E', 'labelled_dir_data39_E', 'labelled_dir_data49_E']}\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "data_dir = 'data/numerical_data_set_simple_torch'\n",
    "\n",
    "filenames = []\n",
    "filenames_by_type = {'A':[], 'B':[], 'C':[], 'D':[], 'E':[]}\n",
    "for file in os.listdir(data_dir):\n",
    "    filename, file_extension = os.path.splitext(file)\n",
    "    \n",
    "    typ = filename[-1]\n",
    "    if typ in filenames_by_type:\n",
    "        filenames.append(file)\n",
    "        filenames_by_type[typ].append(file)\n",
    "        \n",
    "print(len(filenames))\n",
    "print(filenames_by_type)\n",
    "for key in filenames_by_type:\n",
    "    print(len(filenames_by_type[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24, 75465, 260])\n",
      "torch.Size([24, 75465, 15])\n",
      "torch.Size([24, 7787, 260])\n",
      "torch.Size([24, 7787, 15])\n",
      "torch.Size([24, 75465, 260])\n",
      "torch.Size([24, 75465, 15])\n",
      "torch.Size([24, 7787, 260])\n",
      "torch.Size([24, 7787, 15])\n",
      "torch.Size([24, 75465, 260])\n",
      "torch.Size([24, 75465, 15])\n",
      "torch.Size([24, 41544, 260])\n",
      "torch.Size([24, 41544, 15])\n",
      "torch.Size([24, 41544, 260])\n",
      "torch.Size([24, 41544, 15])\n",
      "18.55167555809021\n",
      "done prepare\n",
      "torch.Size([24, 331308, 260])\n",
      "torch.Size([24, 331308, 15])\n",
      "done chunking\n",
      "0.09187698364257812\n",
      "512\n",
      "648\n",
      "648\n",
      "torch.Size([24, 512, 260])\n",
      "torch.Size([24, 512, 15])\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "df = pd.DataFrame({'Attribute_value':[], 'Numerical_value':[]})\n",
    "for filename in filenames_by_type['E'][:-1]:\n",
    "    print(filename)\n",
    "    dfE = pd.read_csv(os.path.join(data_dir,filename))\n",
    "    #dfE[['Attribute_value','Numerical_Value']]\n",
    "    df = pd.concat([df,dfE[['Attribute_value','Numerical_value']]])\n",
    "    print(len(df))\n",
    "\n",
    "                 \n",
    "#df = pd.read_csv(os.path.join(data_dir,filenames[0])\n",
    "\n",
    "inputs = df['Attribute_value']\n",
    "targets = df['Numerical_value']\n",
    "'''\n",
    "data_dir = 'data/numerical_data_set_simple_torch'\n",
    "\n",
    "start=time.time()\n",
    "filename=filenames_by_type['E'][0]\n",
    "q = torch.load(os.path.join(data_dir,filename))\n",
    "inputs,targets = q[0],q[1]\n",
    "\n",
    "for filename in filenames_by_type['E'][1:]:\n",
    "    q = torch.load(os.path.join(data_dir,filename))\n",
    "    src,trg = q[0],q[1]\n",
    "    print(src.size())\n",
    "    print(trg.size())\n",
    "    inputs=torch.cat([inputs,src],dim=1)\n",
    "    targets=torch.cat([targets,trg],dim=1)\n",
    "        \n",
    "\n",
    "BATCH_SIZE=512\n",
    "n_chunks = math.ceil(inputs.size()[1]/BATCH_SIZE)\n",
    "\n",
    "\n",
    "#inputs = prepare_data(inputs)\n",
    "#targets = prepare_targets(targets)\n",
    "print(time.time()-start)\n",
    "print('done prepare')\n",
    "\n",
    "print((inputs).size())\n",
    "print((targets).size())\n",
    "\n",
    "#print('input')\n",
    "#print(inputs[:,0,:])\n",
    "#print('target')\n",
    "#print(targets[:,0,:])\n",
    "#print(torch.argmax(targets, dim=2)[:,0])\n",
    "\n",
    "start=time.time()\n",
    "inputs = torch.chunk(inputs, n_chunks, dim=1) \n",
    "targets = torch.chunk(targets, n_chunks, dim=1) \n",
    "\n",
    "print('done chunking')\n",
    "print(time.time()-start)\n",
    "print(BATCH_SIZE)\n",
    "print(n_chunks)\n",
    "print(len(inputs))\n",
    "print((inputs[0].size()))\n",
    "print((targets[0].size()))\n",
    "\n",
    "#print((inputs[3].size()))\n",
    "#print((targets[3].size()))\n",
    "\n",
    "print('done')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "time 395.94718527793884\n",
      "loss 1.7883344169384168\n",
      "epoch 1\n",
      "time 397.3986928462982\n",
      "loss 1.8470590526675001\n",
      "epoch 2\n",
      "time 407.896625995636\n",
      "loss 1.7315473764398952\n",
      "epoch 3\n",
      "time 388.6928918361664\n",
      "loss 1.4765218209337305\n",
      "epoch 4\n",
      "time 390.40739345550537\n",
      "loss 0.9203645781510406\n",
      "epoch 5\n",
      "time 393.8921866416931\n",
      "loss 0.5513821186750759\n",
      "epoch 6\n",
      "time 394.3046269416809\n",
      "loss 0.429654762516787\n",
      "epoch 7\n",
      "time 390.69056367874146\n",
      "loss 0.3873074577638396\n",
      "epoch 8\n",
      "time 394.3005497455597\n",
      "loss 0.3724944071361312\n",
      "epoch 9\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c0f74b681f33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomputing_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mepoch_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-6383319efeea>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, inputs, targets, optimizer, criterion, computing_device)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_forcing_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# grab indices for loss function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/datasets/home/home-00/08/808/res001/cse291/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, trg, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mpred_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred_max\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;31m#top1 = output.max(1)[1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "epoch_losses =[]\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('epoch', epoch)\n",
    "    start=time.time()\n",
    "    loss = train(model, inputs, targets, optimizer, criterion, computing_device)\n",
    "    epoch_losses.append(loss)\n",
    "    print('time',time.time()-start)\n",
    "    print('loss',loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"./output/typeE_9.pt\"\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "y = [1.7883344169384168,1.8470590526675001,1.7315473764398952,1.4765218209337305,0.9203645781510406,0.5513821186750759,0.429654762516787,0.3873074577638396,0.3724944071361312]\n",
    "x = list(range(len(y)))\n",
    "\n",
    "plt.plot(x,y)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('cross entropy')\n",
    "plt.title('Training on type E')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
